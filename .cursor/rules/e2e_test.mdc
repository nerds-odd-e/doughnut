---
description: e2e test /end to end test / system test / integrated test guildeline
alwaysApply: false
---
# E2E Testing Practices for Doughnut

## Development Environment Assumption

**IMPORTANT**: Always assume that the developer has already started all services using `pnpm sut`, which includes:
- Backend (with auto-reload on Java code changes)
- Frontend (with hot module replacement)
- Mountebank (mock services)

All services automatically restart when code changes are made. The developer does NOT need to manually restart services when making changes.

**If services are not running**, suggest the user to run `pnpm sut` in a separate terminal first.

## Run E2E Test in Terminal

We usually don't run all the e2e tests locally, since it will take too much time. To run one feature file:

```
nix develop -c pnpm cypress run --spec e2e_test/features/ai_generated_recall_questions/question_contest.feature
```

Note: don't use `cypress run -- --spec`. The empty `--` will ignore the `--spec` parameter after it.

If a scenario has the "@focus" tag, the other scenarios in the same feature file are ignored.

## Technology Stack
- Cypress for E2E testing
- Cucumber plugin for BDD-style tests
- TypeScript for type safety and better IDE support
- Mountebank is used to mock external services.

## Project Structure
- `e2e_test` contains all the tests
- `e2e_test/features` contains the BDD-style tests
- `e2e_test/step_definitions` contains the step definitions for the tests
- `e2e_test/start/` contains the page objects for the tests
- `e2e_test/support/` contains the support files for the tests

## Debugging

The backend service log is located at `backend/logs/doughnut-e2e.log`. Please make sure only get tail from it.

## Key Practices

### 1. BDD with Cucumber

- Write features in Gherkin syntax focusing on business value
- Group related features in domain-specific folders
- Use tags (e.g., `@usingMockedOpenAiService`, `@mockBrowserTime`) to control test execution
- Keep scenarios focused and concise

### 2. Step Definitions

- Keep step definitions lightweight
- Delegate implementation details to Page Objects
- Use TypeScript for better type safety
- Reuse steps across features when possible
- Use parameter types for complex objects

Example:
```typescript
When('I start a conversation about the note {string}', (noteTopology: string) => {
  start.jumpToNotePage(noteTopology).startAConversationAboutNote()
})
```

### 3. Page Object Pattern

- Centralize all UI interactions in page objects
- Chain methods for better readability
- Use TypeScript interfaces for better type checking
- Keep page objects focused on single responsibility
- Use meaningful method names that reflect user actions

Example:
```typescript
const notePage = {
  startAConversationAboutNote() {
    this.toolbarButton('Star a conversation').click()
    return conversationPage()
  }
}
```

### 4. Test Data Management

- Use Given steps to set up test data
- Mock external services when appropriate (e.g., OpenAI)
- Clean up test data after each test
- Use data tables for complex test data

Example:
```gherkin
Given there are some notes:
  | Title    | Parent Title | Skip Memory Tracking |
  | Shape    |              | true        |
  | Square   | Shape        |             |
```

### 5. Service Mocking

- Mock external services (e.g., OpenAI) for reliable tests
- Use tags to indicate when mocks are required
- Keep mock responses consistent with real service behavior
- Store mock data separately from test code

Example:
```typescript
Given('OpenAI assistant will reply below for user messages in a stream run:', (data: DataTable) => {
  mock_services.openAi()
    .stubCreateThread('thread-123')
    .createThreadAndStubMessages('thread-123', data.hashes())
})
```

### 6. Best Practices

1. **Test Organization**
   - Group related features in domain folders
   - Use meaningful file names
   - Keep scenarios focused on single functionality

2. **Code Quality**
   - Use TypeScript for better maintainability
   - Follow consistent naming conventions
   - Document complex test setups

3. **Maintainability**
   - Keep step definitions simple
   - Reuse page objects and helpers
   - Use meaningful descriptions in feature files
   - Document complex test scenarios

## Common Pitfalls to Avoid

1. Don't put complex logic in step definitions
2. Don't create long scenarios with many steps
3. Don't rely on test order
4. Don't use hardcoded waits
5. Don't skip error handling
6. Don't mix different levels of abstraction in scenarios
